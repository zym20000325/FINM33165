{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ed9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "pyplot.plot([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "import pandas as pd\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta,AutoNormal\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, Trace_ELBO, config_enumerate, infer_discrete\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d18e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = [1/2,1/3,1/6]\n",
    "mu = [1.0,5.0,10.0]\n",
    "sigma2 = [1.0,1.5,2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "data = []\n",
    "\n",
    "#first we generate n_samples samples from the distribution pi i.e. a sequece of the form {1,3,1,2,1,3,3,2,.....}\n",
    "cluster_assignments = np.random.choice(3,n_samples,p=pi)\n",
    "\n",
    "\n",
    "# for each of the indices in cluster_assignments we sample from the Normal(mu[idx],sigma2[idx]) distribution\n",
    "for assignment in cluster_assignments:\n",
    "    mean = mu[assignment]\n",
    "    var = sigma2[assignment]\n",
    "    sample = np.random.normal(mean,var)\n",
    "    data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience we structure the data set as a pandas DataFrame\n",
    "df = pd.DataFrame(data=data,columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa533715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the data as a tensor\n",
    "data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65345b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc86a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this code displays the histogram of the data set with a smooth curve overlaid\n",
    "import seaborn as sns\n",
    "\n",
    "pyplot.rcParams[\"figure.figsize\"] = (14,14)\n",
    "\n",
    "ax = df['data'].plot.hist(bins=100, density=True, edgecolor='w', linewidth=2.5)\n",
    "\n",
    "# Save default x-axis limits for final formatting because the pandas kde\n",
    "# plot uses much wider limits which usually decreases readability\n",
    "xlim = ax.get_xlim()\n",
    "\n",
    "# Plot pandas KDE\n",
    "df['data'].plot.density(color='r', linewidth = 10,alpha=1, ax=ax) # same as df['var'].plot.kde()\n",
    "\n",
    "# Reset x-axis limits and edit legend and add title\n",
    "ax.set_xlim(xlim)\n",
    "ax.legend(labels=['KDE'], frameon=False)\n",
    "ax.set_title('Pandas histogram overlaid with KDE', fontsize=14, pad=15)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0320fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first have to define the pyro model. We first specify the prior. There are three groups of parameters: the weights i.e.\n",
    "# the distribution over {0,1,2}, the means for each of the tree Gaussians and their variances. These are all independent so\n",
    "# the prior is a product of the distributions over each parameter\n",
    "K=3\n",
    "\n",
    "@config_enumerate\n",
    "def model(data):\n",
    "    samples = []\n",
    "    # the distribution pi is sampled from a Dirichlet distribution. The Dirichlet is a distribution over the\n",
    "    # probability simplex i.e. all vectors $x_1,x_2,...,x_n$ with x_i > 0 and summing up to 1\n",
    "    # each of the parameters are stored in the pyro.param_store as items in a dict, as we can see they all have to be named.\n",
    "    # In pyro distributions are basically characterized by their samples\n",
    "    weights=pyro.sample('weights',dist.Dirichlet(0.5*torch.ones(K)))\n",
    "    \n",
    "    #the pyro.plate specifies an array of independent distributions. Here the distribution for each of the means is a\n",
    "    #Gaussian with mean 0 and variance 10, the variances have a LogNormal distribution since the have to be > 0.\n",
    "    # these distributions are stored in an array in the param_store named 'components'\n",
    "    with pyro.plate('components',K):\n",
    "        #the prior distriburion of the means\n",
    "        locs = pyro.sample('locs',dist.Normal(0.,10.))\n",
    "        # the prior distribution of the variances\n",
    "        scales = pyro.sample('scales',dist.LogNormal(0.,2.))\n",
    "        \n",
    "    #here is the likelihood, for each data point an assignment to a Gaussian and then it is a sample from that Gaussian\n",
    "    # first a sample from the distribution pi, which in turn is a sample from the Dirichlet distribution above.\n",
    "    # then a sample from the corresponding Gaussian with mean and variance sampled from the appropriate priors\n",
    "    with pyro.plate('data',len(data)):\n",
    "        assignment = pyro.sample('assignment',dist.Categorical(weights))\n",
    "        pyro.sample('obs',dist.Normal(locs[assignment],scales[assignment]),obs=data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = [1/2,1/3,1/6]\n",
    "mu = [1.0,5.0,10.0]\n",
    "sigma2 = [1.0,1.5,2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e199d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import the appropriate pyro packages\n",
    "\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from pyro.infer.mcmc import HMC,NUTS,MCMC\n",
    "pyro.set_rng_seed(2)\n",
    "kernel = NUTS(model)\n",
    "mcmc = MCMC(kernel,num_samples=1000,warmup_steps=50)\n",
    "mcmc.run(data)\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples['locs'].numpy()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.hist(posterior_samples['locs'].numpy()[:,0],bins=100,density=True);\n",
    "pyplot.hist(posterior_samples['locs'].numpy()[:,1],bins=100,density=True);\n",
    "pyplot.hist(posterior_samples['locs'].numpy()[:,2],bins=100,density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.hist(posterior_samples['scales'].numpy()[:,0],bins=100,density=True);\n",
    "pyplot.hist(posterior_samples['scales'].numpy()[:,1],bins=100,density=True);\n",
    "pyplot.hist(posterior_samples['scales'].numpy()[:,2],bins=100,density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.hist(posterior_samples['weights'].numpy()[:,0],bins=100,density=True);\n",
    "pyplot.hist(posterior_samples['weights'].numpy()[:,1],bins=100,density=True);\n",
    "pyplot.hist(posterior_samples['weights'].numpy()[:,2],bins=100,density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples['locs'][500:].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples['scales'].numpy()[500:].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples['weights'].numpy()[500:].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3707c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
