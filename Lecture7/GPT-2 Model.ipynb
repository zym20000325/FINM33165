{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fed10bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import kaiming_normal_\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4b17610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :]+\\\n",
    "                 self.pos_embedding[:token_embedding.size(0), :])\n",
    "        \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a03e942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7288e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Model(nn.Module):\n",
    "    def __init__(self,embedding_dim=512,vocab_sz=12000,d_model=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.d_model = d_model\n",
    "        self.vocab_sz = vocab_sz\n",
    "    \n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_sz,self.embedding_dim,padding_idx=0).to(torch.float)\n",
    "        \n",
    "        self.emb_weight = nn.Parameter(self.embedding.weight)\n",
    "        \n",
    "        self.position_emb = PositionalEncoding(emb_size=self.embedding_dim,\n",
    "                                              dropout=0.02)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.embedding_dim,self.d_model)\n",
    "        \n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=512,nhead=8,\n",
    "                                                       batch_first=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,seq):\n",
    "        \n",
    "        s = self.embedding(seq[:,:-1])\n",
    "        \n",
    "        s = self.position_emb(s)\n",
    "        \n",
    "        sz = s.shape[1] #seq length\n",
    "        \n",
    "        mask = generate_square_subsequent_mask(sz)\n",
    "        \n",
    "        transformer = nn.TransformerDecoder(self.decoder_layer, num_layers=6)\n",
    "                                             \n",
    "        out = transformer(tgt=s,memory=s,tgt_mask=mask) \n",
    "        \n",
    "        out = out @ self.embedding.weight.T\n",
    "        \n",
    "        return F.softmax(out,dim=1)\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d712784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT2Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a56830cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.randint(12000,(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4587b9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1444,  6866, 10298,  5349,  8742,  4656,  4974,  1553,  5392,  8350,\n",
       "          7766,  5875,  6813,  5359,  1348],\n",
       "        [ 5421,  7495,  5031, 10265,  4535,  5024,  2605,  9636,  5759,  5241,\n",
       "          7620,   498,  6163,   155,  4595],\n",
       "        [ 4922,  5422, 11667, 10973,  3140, 11864,  3417,  7335,  9431,  5849,\n",
       "          7014,   473, 11552,  9431,  3023],\n",
       "        [ 6025,  4873,   850,  6919,  7008,  9700,  2830,  9614,  5624,  7398,\n",
       "         10037,  3465, 11286,  4638,  3101],\n",
       "        [11191,  8705,  1452,  6506,  8122,  3990,  9915,  1362,  4087,   437,\n",
       "          1608,   550,  1931,  9101,  8699],\n",
       "        [  901, 11774,  5921, 10341, 10574,  5068,   124,  7600,  5595,  9150,\n",
       "          9863, 11509,  8178,  9247,  8061],\n",
       "        [10469,  6485,  2340,  2692,  3427,  2365,    53,  8785,  5364, 10366,\n",
       "          5740,  1264,  5529,  5776,  7627],\n",
       "        [ 2375,  1569,  6195,  7976,  5548,  7011, 11130,  8561,  4736,  9652,\n",
       "          3656, 11413,  9062,  3189,  3810],\n",
       "        [ 4676,  5561,  8216,   778,  6826,    47,  8206,  2538, 10565, 10234,\n",
       "         10200,  4845,  8001,  5277,  1726],\n",
       "        [10176,  5870,  7479,  9463,   768,  1670,  7798, 10928,  7660,  5889,\n",
       "          3638,  4118, 11124,  5845, 11933],\n",
       "        [ 2225,  8438,  6993,  2468,  2430, 10019,  2162,  2938,  6186,  4915,\n",
       "          5242,  5579,  3712,  6114,  9244],\n",
       "        [ 2190,  2872,  5647,  3613,  1916,  8230,  7934,   671,  7422, 10894,\n",
       "          6082,  9975,  1042,  2782,  5497],\n",
       "        [  376,  8118, 10286,  1821,   123,  3336,  7767,  5801,  5284,  4471,\n",
       "          6670,  7626,  4430, 10593,    61],\n",
       "        [    1,   236,  6907, 10426,  1783,  5610, 10616,  4977,  5716,   547,\n",
       "          8425,  3685,    33,  6429,  6951],\n",
       "        [ 3123,  1371,  7783,  1558,  9146,  5942, 10765,   522,  4432,  6821,\n",
       "          2523,  8093,  6263,  2337,   889],\n",
       "        [10099,  4217,  9923,  8168,  7678,  9598,  8252, 11009,   322, 11615,\n",
       "          3263,  1667,  8642,  2216,  7066],\n",
       "        [ 3452, 11457,  6820,  3916,   632,  9979, 10481,  7642,  8093,  7956,\n",
       "          8986,  2773,  4198,  3256, 11780],\n",
       "        [ 5717,   157,   709,  7988,    18,  4727, 10207,   991,  4920,  8738,\n",
       "          1923,  3623,   156,  8016,  6906],\n",
       "        [ 5442,  8429,  5909,  1722,  6294,  5622,  9489,  3471,  2216,  4539,\n",
       "          9189, 11833, 10406, 11389, 10417],\n",
       "        [ 5393,  4869, 10877,  2046,  6971,  6052,  3401,  8721,  7342,  7216,\n",
       "          9075, 11759,  6205, 10225,  7931]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f3b381c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = gpt(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9094e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 14, 12000])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9272876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0445, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss()(output.view(output.shape[0]*output.shape[1],-1),seq[:,1:].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ebe60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
